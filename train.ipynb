{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22ec96d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from model import build_model\n",
    "import tqdm\n",
    "from data import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e93dd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Generator, Descriminator\n",
    "generator = Generator(latent_dim=256)\n",
    "descriminator = Descriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abc906fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (seq_pipe): Sequential(\n",
       "    (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.01)\n",
       "    (9): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (10): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): LeakyReLU(negative_slope=0.01)\n",
       "    (12): ConvTranspose2d(16, 1, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (13): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4659db08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Descriminator(\n",
       "  (descriminator): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Conv2d(128, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.01)\n",
       "    (9): Flatten(start_dim=1, end_dim=-1)\n",
       "    (10): Linear(in_features=1152, out_features=64, bias=True)\n",
       "    (11): LeakyReLU(negative_slope=0.01)\n",
       "    (12): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (13): LeakyReLU(negative_slope=0.01)\n",
       "    (14): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (15): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c52ae0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(generator: Generator, descriminator: Descriminator, test_loader, num_data, batch_size, device):\n",
    "    generator.eval()\n",
    "    descriminator.eval()\n",
    "    progress_bar = tqdm.tqdm(test_loader)\n",
    "    generator_losses = []\n",
    "    descriminator_losses = []\n",
    "    for i, (images, _) in enumerate(progress_bar):\n",
    "      with torch.no_grad():\n",
    "          real_img_batch = images.to(device)\n",
    "          fake_img_batch = generator(batch_size)\n",
    "            \n",
    "          real_labels = torch.ones(size=(batch_size, ), device=device)\n",
    "          fake_labels = torch.zeros(size=(batch_size, ), device=device)\n",
    "            \n",
    "          # Descriminate\n",
    "          real_desc_pred = descriminator(real_img_batch).squeeze() # (5, 1)\n",
    "          fake_desc_pred = descriminator(fake_img_batch).squeeze() # Descrimating Generated image\n",
    "            \n",
    "          real_desc_loss = F.binary_cross_entropy(real_desc_pred, real_labels)\n",
    "          fake_desc_loss = F.binary_cross_entropy(fake_desc_pred, fake_labels)\n",
    "          descriminator_loss = (real_desc_loss + fake_desc_loss) / 2.0\n",
    "          \n",
    "          fake_img_batch = generator(batch_size)\n",
    "          fake_desc_pred = descriminator(fake_img_batch).squeeze()\n",
    "          generator_loss = F.binary_cross_entropy(fake_desc_pred, real_labels)\n",
    "          \n",
    "          generator_losses.append(generator_loss.item())\n",
    "          descriminator_losses.append(descriminator_loss.item())\n",
    "          \n",
    "      if i == num_data:\n",
    "          break\n",
    "    \n",
    "    eval_generator_mean_loss = torch.tensor(generator_losses).mean()\n",
    "    eval_descriminator_mean_loss = torch.tensor(descriminator_losses).mean()\n",
    "    \n",
    "    img = generator(1).squeeze().detach().cpu()\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(\"Generated Image\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    generator.train()\n",
    "    descriminator.train()\n",
    "    \n",
    "    return eval_descriminator_mean_loss, eval_generator_mean_loss\n",
    " \n",
    "def train(generator, descriminator, num_epochs, eval_epoch, device, batch_size):\n",
    "    generator.to(device)\n",
    "    descriminator.to(device)\n",
    "    descriminator_optimizer = torch.optim.AdamW(descriminator.parameters(), lr=1e-4)\n",
    "    generator_optimizer = torch.optim.AdamW(generator.parameters(), lr=1e-4)\n",
    "    train_loader, test_loader = load_data(train_batch_size=batch_size, test_batch_size=2)\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        progress = tqdm.tqdm(train_loader, dynamic_ncols=True)\n",
    "        generator.train()\n",
    "        descriminator.train()\n",
    "        progress.set_description(f'Epoch: {epoch}')\n",
    "        generator_losses = []\n",
    "        descriminator_losses = []\n",
    "        \n",
    "        for images, _ in progress:\n",
    "            real_img_batch = images.to(device)\n",
    "            fake_img_batch = generator(batch_size)\n",
    "            \n",
    "            real_labels = torch.ones(size=(batch_size, ), device=device)\n",
    "            fake_labels = torch.zeros(size=(batch_size, ), device=device)\n",
    "            \n",
    "            # Descriminate\n",
    "            real_desc_pred = descriminator(real_img_batch).squeeze() # (5, 1)\n",
    "            fake_desc_pred = descriminator(fake_img_batch).squeeze() # Descrimating Generated image\n",
    "            \n",
    "            real_desc_loss = F.binary_cross_entropy(real_desc_pred, real_labels)\n",
    "            fake_desc_loss = F.binary_cross_entropy(fake_desc_pred, fake_labels)\n",
    "            descriminator_loss = (real_desc_loss + fake_desc_loss) / 2.0\n",
    "        \n",
    "            descriminator_loss.backward()\n",
    "            descriminator_optimizer.step()\n",
    "            descriminator_optimizer.zero_grad()\n",
    "            \n",
    "            fake_img_batch = generator(batch_size)\n",
    "            fake_desc_pred = descriminator(fake_img_batch).squeeze()\n",
    "            generator_loss = F.binary_cross_entropy(fake_desc_pred, real_labels)\n",
    "            generator_loss.backward()\n",
    "            generator_optimizer.step()\n",
    "            generator_optimizer.zero_grad()\n",
    "            \n",
    "            generator_losses.append(generator_loss.item())\n",
    "            descriminator_losses.append(descriminator_loss.item())\n",
    "            \n",
    "            progress.set_postfix({'generator_loss': generator_loss.item(), 'descriminator_loss': descriminator_loss.item()})\n",
    "            \n",
    "      \n",
    "        generator_mean_loss = torch.tensor(generator_losses).mean()\n",
    "        descriminator_mean_loss = torch.tensor(descriminator_losses).mean()\n",
    "       \n",
    "        if epoch > 1 :\n",
    "          eval_descriminator_loss, eval_generator_loss = evaluate(generator, descriminator,test_loader, num_data=20, batch_size=2, device='cuda')\n",
    "          progress.set_postfix({'generator_loss': generator_mean_loss, 'descriminator_loss': descriminator_mean_loss, 'eval_gen_loss': eval_generator_loss, 'eval_des_loss':eval_descriminator_loss})\n",
    "        else:\n",
    "         progress.set_postfix({'generator_loss': generator_mean_loss, 'descriminator_loss': descriminator_mean_loss})\n",
    "       \n",
    "      \n",
    "          \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eeb7fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(generator: Generator, discriminator: Descriminator, test_loader, num_data, batch_size, device):\n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "    progress_bar = tqdm.tqdm(test_loader)\n",
    "    generator_losses = []\n",
    "    discriminator_losses = []\n",
    "    for i, (images, _) in enumerate(progress_bar):\n",
    "        with torch.no_grad():\n",
    "            real_img_batch = images.to(device)\n",
    "            fake_img_batch = generator(batch_size)\n",
    "            \n",
    "            real_labels = torch.ones(size=(batch_size, ), device=device)\n",
    "            fake_labels = torch.zeros(size=(batch_size, ), device=device)\n",
    "            \n",
    "            # Discriminate\n",
    "            real_desc_pred = discriminator(real_img_batch).squeeze()\n",
    "            fake_desc_pred = discriminator(fake_img_batch).squeeze()\n",
    "            \n",
    "            real_desc_loss = F.binary_cross_entropy_with_logits(real_desc_pred, real_labels)\n",
    "            fake_desc_loss = F.binary_cross_entropy_with_logits(fake_desc_pred, fake_labels)\n",
    "            discriminator_loss = (real_desc_loss + fake_desc_loss) / 2.0\n",
    "            \n",
    "            # Generator evaluation\n",
    "            fake_img_batch = generator(batch_size)\n",
    "            fake_desc_pred = discriminator(fake_img_batch).squeeze()\n",
    "            generator_loss = F.binary_cross_entropy_with_logits(fake_desc_pred, real_labels)\n",
    "            \n",
    "            generator_losses.append(generator_loss.item())\n",
    "            discriminator_losses.append(discriminator_loss.item())\n",
    "            \n",
    "        if i >= num_data:  # Use >= instead of ==\n",
    "            break\n",
    "    \n",
    "    eval_generator_mean_loss = torch.tensor(generator_losses).mean()\n",
    "    eval_discriminator_mean_loss = torch.tensor(discriminator_losses).mean()\n",
    "    \n",
    "    img = generator(1).squeeze().detach().cpu()\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(\"Generated Image\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    \n",
    "    return eval_discriminator_mean_loss, eval_generator_mean_loss\n",
    "\n",
    "def train(generator, discriminator, num_epochs, eval_epoch, device, batch_size):\n",
    "    generator.to(device)\n",
    "    discriminator.to(device)\n",
    "    \n",
    "    # Different learning rates - often helps with stability\n",
    "    discriminator_optimizer = torch.optim.AdamW(discriminator.parameters(), lr=5e-4, betas=(0.5, 0.999))\n",
    "    generator_optimizer = torch.optim.AdamW(generator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    \n",
    "    train_loader, test_loader = load_data(train_batch_size=batch_size, test_batch_size=2)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        progress = tqdm.tqdm(train_loader, dynamic_ncols=True)\n",
    "        generator.train()\n",
    "        discriminator.train()\n",
    "        progress.set_description(f'Epoch: {epoch}')\n",
    "        generator_losses = []\n",
    "        discriminator_losses = []\n",
    "        \n",
    "        for images, _ in progress:\n",
    "            real_img_batch = images.to(device)\n",
    "            batch_size_actual = real_img_batch.size(0)  # Handle variable batch sizes\n",
    "            \n",
    "            real_labels = torch.ones(size=(batch_size_actual,), device=device) + 0.3 * torch.randn(size=(batch_size_actual,), device=device)\n",
    "            fake_labels = torch.zeros(size=(batch_size_actual,), device=device) - 0.3 * torch.randn(size=(batch_size_actual,), device=device)\n",
    "            \n",
    "            # === Train Discriminator ===\n",
    "            discriminator_optimizer.zero_grad()\n",
    "            \n",
    "            # Real images\n",
    "            real_desc_pred = discriminator(real_img_batch).squeeze()\n",
    "            real_desc_loss = F.binary_cross_entropy_with_logits(real_desc_pred, real_labels)\n",
    "            \n",
    "            # Fake images (detach to prevent generator gradients)\n",
    "            fake_img_batch = generator(batch_size_actual).detach()  # DETACH HERE\n",
    "            fake_desc_pred = discriminator(fake_img_batch).squeeze()\n",
    "            fake_desc_loss = F.binary_cross_entropy_with_logits(fake_desc_pred, fake_labels)\n",
    "            \n",
    "            discriminator_loss = (real_desc_loss + fake_desc_loss) / 2.0\n",
    "            discriminator_loss.backward()\n",
    "            discriminator_optimizer.step()\n",
    "            \n",
    "            # === Train Generator ===\n",
    "            generator_optimizer.zero_grad()\n",
    "            \n",
    "            # Generate new fake images (don't detach - we want gradients)\n",
    "            fake_img_batch = generator(batch_size_actual)\n",
    "            fake_desc_pred = discriminator(fake_img_batch).squeeze()\n",
    "            generator_loss = F.binary_cross_entropy_with_logits(fake_desc_pred, real_labels)\n",
    "            \n",
    "            generator_loss.backward()\n",
    "            generator_optimizer.step()\n",
    "            \n",
    "            generator_losses.append(generator_loss.item())\n",
    "            discriminator_losses.append(discriminator_loss.item())\n",
    "            \n",
    "            progress.set_postfix({\n",
    "                'gen_loss': f\"{generator_loss.item():.4f}\", \n",
    "                'disc_loss': f\"{discriminator_loss.item():.4f}\"\n",
    "            })\n",
    "        \n",
    "        generator_mean_loss = torch.tensor(generator_losses).mean()\n",
    "        discriminator_mean_loss = torch.tensor(discriminator_losses).mean()\n",
    "        \n",
    "        if epoch > 1:\n",
    "            eval_discriminator_loss, eval_generator_loss = evaluate(\n",
    "                generator, discriminator, test_loader, num_data=20, batch_size=2, device=device\n",
    "            )\n",
    "            progress.set_postfix({\n",
    "                'gen_loss': f\"{generator_mean_loss:.4f}\", \n",
    "                'disc_loss': f\"{discriminator_mean_loss:.4f}\", \n",
    "                'eval_gen': f\"{eval_generator_loss:.4f}\", \n",
    "                'eval_disc': f\"{eval_discriminator_loss:.4f}\"\n",
    "            })\n",
    "        else:\n",
    "            progress.set_postfix({\n",
    "                'gen_loss': f\"{generator_mean_loss:.4f}\", \n",
    "                'disc_loss': f\"{discriminator_mean_loss:.4f}\"\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8c8f6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0: 100%|██████████| 1875/1875 [00:34<00:00, 54.20it/s, gen_loss=0.6931, disc_loss=0.5086]\n",
      "Epoch: 1: 100%|██████████| 1875/1875 [00:34<00:00, 54.17it/s, gen_loss=0.6931, disc_loss=0.5139]\n",
      "Epoch: 2: 100%|██████████| 1875/1875 [00:34<00:00, 54.57it/s, gen_loss=0.6931, disc_loss=0.4265]\n",
      "  0%|          | 20/5000 [00:00<00:22, 217.29it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3:  28%|██▊       | 532/1875 [00:10<00:25, 52.14it/s, gen_loss=0.6931, disc_loss=0.5066]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 100\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(generator, discriminator, num_epochs, eval_epoch, device, batch_size)\u001b[0m\n\u001b[0;32m     97\u001b[0m generator_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     98\u001b[0m generator_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 100\u001b[0m generator_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mgenerator_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    101\u001b[0m discriminator_losses\u001b[38;5;241m.\u001b[39mappend(discriminator_loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m    103\u001b[0m progress\u001b[38;5;241m.\u001b[39mset_postfix({\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgen_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerator_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisc_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiscriminator_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m })\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(generator=generator, discriminator=descriminator, num_epochs=100, eval_epoch=20, device='cuda', batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0b6885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAN-FROM-SCRATCH-PYTORCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
